---
layout: post
title: Pandas Crash Course
---

<img src="/Images/pandas.jpg" class="inline"/><br>
Your data will be good to you, if you're good to it. Be responsible, use Pandas. 

# Loading Data:

First, you'll need to import the library, using the keyword 'as' allows us to reference the library
by simply using pd as a way to call a feature in Pandas. Ex. `pd.value_counts()`

`import pandas as pd`

Now, we can use the feature `read_csv()` to construct a call to the file that contains our data.

`raw = pd.read_csv('filepath/filename.csv')`

Great! 

That was easy, but <b>it won't always be easy</b>. Your file may have an improper format at the initial read-state, but we can remedy this with available attributes we can define in the `.read_csv` call.

`pandas.read_csv(filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='"', quoting=0, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=False, error_bad_lines=True, warn_bad_lines=True, skip_footer=0, doublequote=True, delim_whitespace=False, as_recarray=False, compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, memory_map=False, float_precision=None)`

...it's a lot to take in this early, so we'll focus on the most common of that long list we would likely find useful.

`sep` - Defines the seperator between values, example, `,`  

`encoding` - Defines the encoding, example UTF8 vs Latin1

`skiprows` - Sets line numbers to skip, or number of lines to skip, ex = [0:2] 

`date_parser` - Converts strings to an array of datetime instances

We can string them together like you'd expect:

`pd.read_csv('filepath/filename.csv', sep = ',', encoding = 'UTF-8', skiprows[1]`

Moving on.

Since we're using Pandas and working with data, you should be excited to utilize a DataFrame, a Pythonic version of the same structure from R. These are wildly useful for every stage of analysis.
We will call `pd.DataFrame()` to produce our desired structure, which we'll store as `df`. 

`df = pd.DataFrame(raw)`

# Data Exploration

Those few steps have allowed us to gather immediate knowledge about our data, and perhaps even our problem we're trying to solve.

Pandas has many native features for data exploration, and we'll cover the most common of which you'll almost always want to use when you are working with a new set of information. 

`.head()` - Returns the observations and variables of top level subset of your dataframe

`.tail()` - Returns the observations and variables of bottom level subset of your dataframe

`.describe()` - Summary of your statistics (min/max, mean, quartiles, standard dev...)

`.info()` - Summary of your dataframe, returns information about datatypes (obj vs int etc)

`.shape` - Returns the count of rows and columns

`value_counts()` - Returns counts of variables and observations (Ex. How many observations for Male vs Female categories respectively)

You'll likely be familiar with most of these if you've used R, many of Pandas' features reproduce the features of R in a more OOP/scriptable/friendly manner. 

Let's look at some example implementations for our dataset.


`pd.shape(df)`

`df.info()`

`df.head()`

`df.tail()`

`df.value_counts()`

`df.describe()`


It's <b>important</b> to explore your data early, you'll avoid some common problems(improper datatypes, missing values, improper naming conventions, duplicate data, and many more), and it's just the proper thing to do. As you explore your data, you can be quite productive. The summary statistics alone are worth your time, but you'll also be developing a knowledge of potential problems; both pre-existing and those down the line. You're taking the first step towards the cleaning stage of the data science process. 

# .DataFrame

We have seemingly limitless control over our data when it's structured in a DataFrame. Slicing, rotating, renaming, refactoring, plotting, insertion and extraction; you can do it all. 

